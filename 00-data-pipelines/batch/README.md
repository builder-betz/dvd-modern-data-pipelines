# Batch Data Pipeline

This batch pipeline focuses on analysing **historical rental** and **engagement data** to uncover long-term user behaviour patterns and content performance trends. By processing structured data at scheduled intervals, the pipeline enables reliable, reproducible analytics that support strategic decision-making, reporting, and deeper behavioural analysis.

The batch approach is well-suited for:

Trend analysis over time

- Aggregations and dimensional modelling

- Business intelligence and performance reporting

Specific, batch-oriented business questions addressed by this pipeline are documented within this page.

## Table of Contents<br/>
- [Business Questions](#business-questions)
- [Dashboard](#dashboard)
- [Source Datasets](#source-datasets)
- [Solution Architecture](#solution-architecture)
- [Testing](#testing)
- [Database Structure](#database-structure)
- [ERD for Dimensional Modeling](#erd-for-dimensional-modeling-star-schema)
- [Data Lineage](#data-lineage)
- [Getting Started](#getting-started)
- [Demo](#demo)


---
üîó **Batch Pipeline Navigation**: 
[Data Source](../../00-data-source/batch/README.md)
| [Data Ingestion](../../01-data-ingestion/batch/README.md)
| [Data Transformation](../../02-data-transformation/batch/README.md)
| [Data Orchestration](../../03-data-orchestration/batch/README.md)
| [Data Consumption](../../04-data-consumption/batch/README.md) 

---

## Business Questions

- Which films have the highest rental volume?
- Which film categories have the highest rental volume?
- What is the rental pattern based on the day of the week?
- Which countries have the highest rental volume?
- Which countries have the longest average rental duration? 


[üîù Return to TOC](#table-of-contents)

## Dashboard

The batch dashboard presents historical user behaviour and content performance trends, enabling consistent reporting and long-term, strategic analysis. Data comes from the one big table (OBT) serving layer of Databricks. For more details, refer to [page](../../04-data-consumption/batch/README.md).

<div align="center">

![Dashboard](../../04-data-consumption/batch/images/batch-preset-dashboard.png)

</div>

[üîù Return to TOC](#table-of-contents)


## Source Datasets

| Source name | Source type | Source documentation | Frequency | 
| - | - | - | - |
| DVD Rentals database | PostgreSQL database | https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/ | Daily |

[üîù Return to TOC](#table-of-contents)

## Solution Architecture

The batch architecture processes historical data on a scheduled basis, transforming it into curated analytical models optimised for reliable reporting and trend analysis.

<div align="center">

![Pipeline Sequence](./images/batch-pipeline-sequence.gif)

</div>

**Architecture Flow:**
1. <img src="https://dagster-website.vercel.app/images/brand/logos/dagster-primary-mark.png" width="24" height="24" alt="Dagster">**Dagster+**: triggers **Airbyte** based on a scheduled cron.
2. <img src="https://cdn.simpleicons.org/airbyte/615EFF" width="24" height="24">**Airbyte**: extracts data from a Postgres RDS source **(A)** and performs a full load into **Databricks Bronze** tables.
3. <img src="https://dagster-website.vercel.app/images/brand/logos/dagster-primary-mark.png" width="24" height="24" alt="Dagster">**Dagster+**: orchestrates dbt Core transformations.
4. <img src="https://www.iconarchive.com/download/i149529/simpleicons-team/simple/dbt.512.png" width="24" height="24" alt="dbt"> **DBT**: performs full-load transformations in **Databricks** from **Bronze ‚Üí Silver**.
5. <img src="https://www.iconarchive.com/download/i149529/simpleicons-team/simple/dbt.512.png" width="24" height="24" alt="dbt" > **DBT**: performs full-load transformations in **Databricks** from **Silver ‚Üí Gold**, producing analytics-ready models.
6. <img src="https://cdn.simpleicons.org/apachesuperset/FF6B35" width="24" height="24"> **Preset dashboards**: query a the **one-big-table (OBT)** generated by the batch pipeline for historical analysis.


[üîù Return to TOC](#table-of-contents)

## Testing

1. **Source freshness checks**: implemented using dbt source freshness tests to ensure data is up to date.
2. **Row count validation**: performed using dbt expectations to compare record counts between Bronze and Silver layers.
3. **Data quality tests**: applied using dbt tests to validate null constraints, uniqueness, and other column-level rules.

## Database Structure

Implemented bronze ‚Üí silver ‚Üí gold data modelling on Databricks database.

| Bronze | Silver | Gold |
| - | - | - | 
| raw_dvd_address | dvd_address | dim_address |
| raw_dvd_category | dvd_category | dim_customer |
| raw_dvd_city | dvd_city | dim_date |
| raw_dvd_country | dvd_country | dim_film |
| raw_dvd_customer | dvd_customer | fact_rental |
| raw_dvd_film | dvd_film | fact_rental_monthly |
| raw_dvd_film_category | dvd_film_category | report_rentals |
| raw_dvd_inventory | dvd_inventory | |
| raw_dvd_payment | dvd_payment | |
| raw_dvd_rental | dvd_rental | |
| (count: 10) | (count: 10) | (count 7) | 

Breakdown of GOLD tables:

| Type | Count | Frequency | Table Name | 
| - | - | - | - | 
| Dimension Table | 4 | Daily | dim_address, dim_customer, dim_film, dim_date  |
| Fact Table | 1 | Daily | fact_rental | 
| Fact Table | 1 | Monthly Snapshot | fact_rental_monthly | 
| One Big Table | 1 | Daily | report_rentals |

<br/>


[üîù Return to TOC](#table-of-contents)

## ERD for Dimensional Modeling (Star Schema)

<div align="center">

![ERD Diagram](../../02-data-transformation/batch/images/batch-star_schema_erd.png)

</div>

[üîù Return to TOC](#table-of-contents)

## Data Lineage 

Data lineage is visualised in Dagster, showing the end-to-end flow from Airbyte ingestion through dbt transformations, alongside dbt‚Äôs native lineage graph for model-level dependencies across Bronze, Silver, and Gold layers.

<div align="center">

![Data Lineage via Dagster+](../../03-data-orchestration/batch/dagster/images/batch-gif-lineage-flow.gif)
![Data Lineage via DBT](../../02-data-transformation/batch/images/batch-dbt-lineage.png)

</div>

[üîù Return to TOC](#table-of-contents)

## Getting Started


### Prerequisites

- <img src="https://cdn.simpleicons.org/python/3776AB" width="24" height="24"> Python 3.13+ (for local development)
- <img src="https://cdn.simpleicons.org/anaconda/44A833" width="24" height="24"> Conda (recommended for environment management)
- Access to:
  - <img src="https://icon.icepanel.io/AWS/svg/Database/RDS.svg" width="24" height="24"> AWS RDS (PostgreSQL) for batch source data
  - <img src="https://cdn.simpleicons.org/databricks/FF3621" width="24" height="24"> Databricks workspace
  - <img src="https://dagster-website.vercel.app/images/brand/logos/dagster-primary-mark.png" width="24" height="24" alt="Dagster"> Dagster+ (or local Dagster)
  - <img src="https://cdn.simpleicons.org/airbyte/615EFF" width="24" height="24"> Airbyte (for data ingestion)
  - <img src="https://cdn.simpleicons.org/apachesuperset/FF6B35" width="24" height="24"> Preset (for dashboards)

### Quick Setup

1. **Set up batch data source:**
   - Follow instructions in [Batch Data Source](../../00-data-source/batch/README.md) to restore the DVD rental database

2. **Install Python dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure components:**
   - **Airbyte:** Set up connection from PostgreSQL to Databricks ([Airbyte Setup](../../01-data-ingestion/batch/README.md))
   - **dbt:** Configure dbt project and profiles ([dbt Setup](../../02-data-transformation/batch/README.md))
   - **Dagster+:** Deploy and configure orchestration ([Dagster Setup](../../03-data-orchestration/batch/README.md))
   - **Preset:** Import dashboard configuration ([Preset Setup](../../04-data-consumption/batch/README.md))

4. **Run the pipeline:**
   - The pipeline runs automatically on a daily schedule via Dagster+ (when you enable the automation)
   - You can also trigger manual runs through the Dagster+ UI

For detailed setup instructions for each component, refer to the [Installation Instructions](#installation-instructions) section below.

[üîù Return to TOC](#table-of-contents)

## Demo

<div align="center">

<img src="https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExNnlrZ3A3MHpjaDRjdDNheGN3NTZ0MDdnNzRvemxoenV2MDc4Y3FnOSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/UdApgUd9hyXbMEexbL/giphy.gif">

</div>

---
üîó **Page Navigation**:  
[Main](../../README.md) 
| Batch 
| [Streaming](../streaming/README.md) 
| [Prev](../../README.md) 
| [Next](../../00-data-source/batch/README.md)

üîó **Batch Pipeline Navigation**: 
[Data Source](../../00-data-source/batch/README.md)
| [Data Ingestion](../../01-data-ingestion/batch/README.md)
| [Data Transformation](../../02-data-transformation/batch/README.md)
| [Data Orchestration](../../03-data-orchestration/batch/README.md)
| [Data Consumption](../../04-data-consumption/batch/README.md) 
